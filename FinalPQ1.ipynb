{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc4bf7-37ab-469a-bddc-8977eaefa236",
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomerID Gender Age Annual Income (k$)Spending Score (1-100)\n",
    "1 Male 19 15 39\n",
    "2 Male 21 15 81\n",
    "3 Female 20 16 6\n",
    "4 Female 23 16 77\n",
    "5 Female 31 17 40\n",
    "6 Female 22 17 76\n",
    "7 Female 35 18 6\n",
    "8 Female 23 18 94\n",
    "9 Male 64 19 3\n",
    "10 Female 30 19 72\n",
    "11 Male 67 19 14\n",
    "12 Female 35 19 99\n",
    "13 Female 58 20 15\n",
    "14 Female 24 20 77\n",
    "15 Male 37 20 13\n",
    "16 Male 22 20 79\n",
    "17 Female 35 21 35\n",
    "18 Male 20 21 66\n",
    "19 Male 52 23 29\n",
    "20 Female 35 23 98\n",
    "21 Male 35 24 35\n",
    "22 Male 25 24 73\n",
    "23 Female 46 25 5\n",
    "24 Male 31 25 73\n",
    "25 Female 54 28 14\n",
    "26 Male 29 28 82\n",
    "27 Female 45 28 32\n",
    "28 Male 35 28 61\n",
    "29 Female 40 29 31\n",
    "30 Female 23 29 87\n",
    "31 Male 60 30 4\n",
    "32 Female 21 30 73\n",
    "33 Male 53 33 4\n",
    "34 Male 18 33 92\n",
    "35 Female 49 33 14\n",
    "36 Female 21 33 81\n",
    "37 Female 42 34 17\n",
    "38 Female 30 34 73\n",
    "39 Female 36 37 26\n",
    "40 Female 20 37 75\n",
    "41 Female 65 38 35\n",
    "42 Male 24 38 92\n",
    "43 Male 48 39 36\n",
    "44 Female 31 39 61\n",
    "45 Female 49 39 28\n",
    "46 Female 24 39 65\n",
    "47 Female 50 40 55\n",
    "48 Female 27 40 47\n",
    "49 Female 29 40 42\n",
    "50 Female 31 40 42\n",
    "51 Female 49 42 52\n",
    "52 Male 33 42 60\n",
    "53 Female 31 43 54\n",
    "54 Male 59 43 60\n",
    "55 Female 50 43 45\n",
    "56 Male 47 43 41\n",
    "57 Female 51 44 50\n",
    "58 Male 69 44 46\n",
    "59 Female 27 46 51\n",
    "60 Male 53 46 46\n",
    "61 Male 70 46 56\n",
    "62 Male 19 46 55\n",
    "63 Female 67 47 52\n",
    "64 Female 54 47 59\n",
    "65 Male 63 48 51\n",
    "66 Male 18 48 59\n",
    "67 Female 43 48 50\n",
    "68 Female 68 48 48\n",
    "69 Male 19 48 59\n",
    "70 Female 32 48 47\n",
    "71 Male 70 49 55\n",
    "72 Female 47 49 42\n",
    "73 Female 60 50 49\n",
    "74 Female 60 50 56\n",
    "75 Male 59 54 47\n",
    "76 Male 26 54 54\n",
    "77 Female 45 54 53\n",
    "78 Male 40 54 48\n",
    "79 Female 23 54 52\n",
    "80 Female 49 54 42\n",
    "81 Male 57 54 51\n",
    "82 Male 38 54 55\n",
    "83 Male 67 54 41\n",
    "84 Female 46 54 44\n",
    "85 Female 21 54 57\n",
    "86 Male 48 54 46\n",
    "87 Female 55 57 58\n",
    "88 Female 22 57 55\n",
    "89 Female 34 58 60\n",
    "90 Female 50 58 46\n",
    "91 Female 68 59 55\n",
    "92 Male 18 59 41\n",
    "93 Male 48 60 49\n",
    "94 Female 40 60 40\n",
    "95 Female 32 60 42\n",
    "96 Male 24 60 52\n",
    "97 Female 47 60 47\n",
    "98 Female 27 60 50\n",
    "99 Male 48 61 42\n",
    "100 Male 20 61 49\n",
    "101 Female 23 62 41\n",
    "102 Female 49 62 48\n",
    "103 Male 67 62 59\n",
    "104 Male 26 62 55\n",
    "105 Male 49 62 56\n",
    "106 Female 21 62 42\n",
    "107 Female 66 63 50\n",
    "108 Male 54 63 46\n",
    "109 Male 68 63 43\n",
    "110 Male 66 63 48\n",
    "111 Male 65 63 52\n",
    "112 Female 19 63 54\n",
    "113 Female 38 64 42\n",
    "114 Male 19 64 46\n",
    "115 Female 18 65 48\n",
    "116 Female 19 65 50\n",
    "117 Female 63 65 43\n",
    "118 Female 49 65 59\n",
    "119 Female 51 67 43\n",
    "120 Female 50 67 57\n",
    "121 Male 27 67 56\n",
    "122 Female 38 67 40\n",
    "123 Female 40 69 58\n",
    "124 Male 39 69 91\n",
    "125 Female 23 70 29\n",
    "126 Female 31 70 77\n",
    "127 Male 43 71 35\n",
    "128 Male 40 71 95\n",
    "129 Male 59 71 11\n",
    "130 Male 38 71 75\n",
    "131 Male 47 71 9\n",
    "132 Male 39 71 75\n",
    "133 Female 25 72 34\n",
    "134 Female 31 72 71\n",
    "135 Male 20 73 5\n",
    "136 Female 29 73 88\n",
    "137 Female 44 73 7\n",
    "138 Male 32 73 73\n",
    "139 Male 19 74 10\n",
    "140 Female 35 74 72\n",
    "141 Female 57 75 5\n",
    "142 Male 32 75 93\n",
    "143 Female 28 76 40\n",
    "144 Female 32 76 87\n",
    "145 Male 25 77 12\n",
    "146 Male 28 77 97\n",
    "147 Male 48 77 36\n",
    "148 Female 32 77 74\n",
    "149 Female 34 78 22\n",
    "150 Male 34 78 90\n",
    "151 Male 43 78 17\n",
    "152 Male 39 78 88\n",
    "153 Female 44 78 20\n",
    "154 Female 38 78 76\n",
    "155 Female 47 78 16\n",
    "156 Female 27 78 89\n",
    "157 Male 37 78 1\n",
    "158 Female 30 78 78\n",
    "159 Male 34 78 1\n",
    "160 Female 30 78 73\n",
    "161 Female 56 79 35\n",
    "162 Female 29 79 83\n",
    "163 Male 19 81 5\n",
    "164 Female 31 81 93\n",
    "165 Male 50 85 26\n",
    "166 Female 36 85 75\n",
    "167 Male 42 86 20\n",
    "168 Female 33 86 95\n",
    "169 Female 36 87 27\n",
    "170 Male 32 87 63\n",
    "171 Male 40 87 13\n",
    "172 Male 28 87 75\n",
    "173 Male 36 87 10\n",
    "174 Male 36 87 92\n",
    "175 Female 52 88 13\n",
    "176 Female 30 88 86\n",
    "177 Male 58 88 15\n",
    "178 Male 27 88 69\n",
    "179 Male 59 93 14\n",
    "180 Male 35 93 90\n",
    "181 Female 37 97 32\n",
    "182 Female 32 97 86\n",
    "183 Male 46 98 15\n",
    "184 Female 29 98 88\n",
    "185 Female 41 99 39\n",
    "186 Male 30 99 97\n",
    "187 Female 54 101 24\n",
    "188 Male 28 101 68\n",
    "189 Female 41 103 17\n",
    "190 Female 36 103 85\n",
    "191 Female 34 103 23\n",
    "192 Female 32 103 69\n",
    "193 Male 33 113 8\n",
    "194 Female 38 113 91\n",
    "195 Female 47 120 16\n",
    "196 Female 35 120 79\n",
    "197 Female 45 126 28\n",
    "198 Male 32 126 74\n",
    "199 Male 32 137 18\n",
    "200 Male 30 137 83\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad478e7-24d5-4ffa-96b4-3885e0dd49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Question1:\n",
    "\n",
    "# a) Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('Mall_Customers.csv')\n",
    "\n",
    "# Selecting features for clustering\n",
    "X = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n",
    "\n",
    "# Standardize the features\n",
    "X_scaled = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Perform K-means clustering with K=5\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# b) Plot the accuracy (Elbow method) of different cluster sizes\n",
    "cluster_sizes = [5, 10, 15, 20, 25, 30]\n",
    "inertia = []\n",
    "\n",
    "for k in cluster_sizes:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the Elbow Method\n",
    "plt.plot(cluster_sizes, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.show()\n",
    "\n",
    "# c) Plot (Scatter) the result based on Annual Income and Spending Score\n",
    "best_cluster_size = 5  # Choose the best cluster size based on the Elbow Method\n",
    "\n",
    "kmeans = KMeans(n_clusters=best_cluster_size, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Plotting the clusters\n",
    "plt.scatter(df['Annual Income (k$)'], df['Spending Score (1-100)'], c=df['Cluster'], cmap='viridis', edgecolors='k', s=50)\n",
    "plt.xlabel('Annual Income (k$)')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.title(f'K-means Clustering (K={best_cluster_size})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50febd0f-1f6f-43ce-a9d9-92ab83ff4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('imdb_dataset.csv')\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(df['review'], df['sentiment'], test_size=0.3, random_state=42)\n",
    "\n",
    "# b) Perform necessary pre-text processing for vocabulary generation\n",
    "\n",
    "# c) Represent the text using TF-IDF feature weighting\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(train_data)\n",
    "test_tfidf = tfidf_vectorizer.transform(test_data)\n",
    "\n",
    "# d) Show the IDF scores of the first 50 keywords in the vocabulary\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "idf_scores = dict(zip(feature_names, tfidf_vectorizer.idf_))\n",
    "\n",
    "# Display IDF scores of the first 50 keywords\n",
    "for keyword, idf_score in list(idf_scores.items())[:50]:\n",
    "    print(f\"{keyword}: {idf_score}\")\n",
    "\n",
    "# e) Perform K-NN classification\n",
    "k_values = list(range(1, 10))\n",
    "scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Initialize and fit K-NN classifier\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_classifier.fit(train_tfidf, train_labels)\n",
    "\n",
    "    # Predict and evaluate accuracy\n",
    "    predictions = knn_classifier.predict(test_tfidf)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    scores.append(accuracy)\n",
    "\n",
    "# Plot KNN testing accuracy for different values of K\n",
    "plt.plot(k_values, scores, marker='o')\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.title('K-NN Classification Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# f) Train the dataset using Random Forest and Logistic Regression\n",
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression(random_state=42)\n",
    "lr_classifier.fit(train_tfidf, train_labels)\n",
    "\n",
    "# g) Compare the performances of different classifiers and show the confusion matrices\n",
    "# K-NN\n",
    "knn_predictions = knn_classifier.predict(test_tfidf)\n",
    "print(\"K-NN Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels, knn_predictions))\n",
    "\n",
    "# Random Forest\n",
    "rf_predictions = rf_classifier.predict(test_tfidf)\n",
    "print(\"\\nRandom Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels, rf_predictions))\n",
    "\n",
    "# Logistic Regression\n",
    "lr_predictions = lr_classifier.predict(test_tfidf)\n",
    "print(\"\\nLogistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels, lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158876bb-bf90-4239-b082-51dc34b29bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# a) Load the train, test, and validation datasets from CSV files into Pandas DataFrame\n",
    "train_df = pd.read_csv('train_emotions.csv')\n",
    "test_df = pd.read_csv('test_emotions.csv')\n",
    "validation_df = pd.read_csv('validation_emotions.csv')\n",
    "\n",
    "# b) Perform necessary pre-text processing for vocabulary generation\n",
    "# (You can use techniques like removing stop words, stemming, etc.)\n",
    "\n",
    "# Example using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "test_tfidf = tfidf_vectorizer.transform(test_df['text'])\n",
    "\n",
    "# c) Train the dataset using Logistic Regression and perform classification evaluation\n",
    "# Logistic Regression\n",
    "lr_classifier = LogisticRegression(random_state=42)\n",
    "lr_classifier.fit(train_tfidf, train_df['emotion'])\n",
    "\n",
    "# Predict and evaluate accuracy\n",
    "test_predictions = lr_classifier.predict(test_tfidf)\n",
    "accuracy = accuracy_score(test_df['emotion'], test_predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_df['emotion'], test_predictions))\n",
    "\n",
    "# d) Use two new sentences as test cases and predict the categories\n",
    "new_sentences = [\"I am feeling extremely happy today!\", \"This news makes me really sad.\"]\n",
    "new_sentences_tfidf = tfidf_vectorizer.transform(new_sentences)\n",
    "predictions = lr_classifier.predict(new_sentences_tfidf)\n",
    "\n",
    "# Display predictions for new sentences\n",
    "print(\"\\nPredictions for New Sentences:\")\n",
    "for sentence, prediction in zip(new_sentences, predictions):\n",
    "    print(f\"Sentence: {sentence} | Predicted Emotion: {prediction}\")\n",
    "\n",
    "# e) Perform K-means Clustering in the training set and plot the accuracy (Elbow method)\n",
    "cluster_range = range(3, 11)\n",
    "inertia_values = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(train_tfidf)\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "\n",
    "# Plot Elbow method\n",
    "plt.plot(cluster_range, inertia_values, marker='o')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal K in K-means Clustering')\n",
    "plt.show()\n",
    "\n",
    "# f) Show the cluster membership of sentences in the test dataset\n",
    "# Assuming the optimal cluster size is determined from the Elbow method\n",
    "optimal_k = 4  # Adjust as per the Elbow method results\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "train_clusters = kmeans.fit_predict(train_tfidf)\n",
    "test_clusters = kmeans.predict(test_tfidf)\n",
    "\n",
    "# Display cluster membership for sentences in the test dataset\n",
    "test_df['cluster'] = test_clusters\n",
    "print(\"\\nCluster Membership in Test Dataset:\")\n",
    "print(test_df[['text', 'emotion', 'cluster']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
